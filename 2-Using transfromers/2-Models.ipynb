{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff2ca266-e52f-463e-8d75-f47173bb21bb",
   "metadata": {},
   "source": [
    "# Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff530b7-03dc-4f30-b1eb-70180306650c",
   "metadata": {},
   "source": [
    "In this section weâ€™ll take a closer look at creating and using a model. Weâ€™ll use the AutoModel class, which is handy when you want to instantiate any model from a checkpoint.\n",
    "\n",
    "The AutoModel class and all of its relatives are actually simple wrappers over the wide variety of models available in the library. Itâ€™s a clever wrapper as it can automatically guess the appropriate model architecture for your checkpoint, and then instantiates a model with this architecture.\n",
    "\n",
    "However, if you know the type of model you want to use, you can use the class that defines its architecture directly. Letâ€™s take a look at how this works with a BERT model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb061176-3501-46b4-bbfb-20e889e49590",
   "metadata": {},
   "source": [
    "## Creating a Transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c9c691-9273-44d0-9d18-6bb962569e92",
   "metadata": {},
   "source": [
    "The first thing weâ€™ll need to do to initialize a BERT model is load a configuration object:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3491bb14-73d9-47da-a5fb-bbcd064eea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "# Building the config\n",
    "config = BertConfig()\n",
    "\n",
    "# Building the model from the config\n",
    "model = BertModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2acee0b2-719a-4aff-8e64-941d426b07b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.7.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1107134a-0a50-459b-bcc1-a7aa8d11f604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96da6ff548b343569deef421b1bc4986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d73a5cf908d488286478227a576268f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e7a1b0-7b16-412d-8e0f-e165cba34058",
   "metadata": {},
   "source": [
    "As you saw earlier, we could replace BertModel with the equivalent AutoModel class. Weâ€™ll do this from now on as this produces checkpoint-agnostic code; if your code works for one checkpoint, it should work seamlessly with another. This applies even if the architecture is different, as long as the checkpoint was trained for a similar task (for example, a sentiment analysis task).\n",
    "\n",
    "In the code sample above we didnâ€™t use BertConfig, and instead loaded a pretrained model via the bert-base-cased identifier. This is a model checkpoint that was trained by the authors of BERT themselves; you can find more details about it in its model card.\n",
    "\n",
    "This model is now initialized with all the weights of the checkpoint. It can be used directly for inference on the tasks it was trained on, and it can also be fine-tuned on a new task. By training with pretrained weights rather than from scratch, we can quickly achieve good results.\n",
    "\n",
    "The weights have been downloaded and cached (so future calls to the from_pretrained method wonâ€™t re-download them) in the cache folder, which defaults to ~/.cache/huggingface/transformers. You can customize your cache folder by setting the HF_HOME environment variable.\n",
    "\n",
    "The identifier used to load the model can be the identifier of any model on the Model Hub, as long as it is compatible with the BERT architecture. The entire list of available BERT checkpoints can be found here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02fe240-4879-4f58-afe7-af527edb787e",
   "metadata": {},
   "source": [
    "## Saving methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa98d25-f8f4-4bfc-add3-8cdf2ba2a14f",
   "metadata": {},
   "source": [
    "Saving a model is as easy as loading one â€” we use the save_pretrained method, which is analogous to the from_pretrained method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f6fe71b-7024-4cff-a72f-55db2a23bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"directory_on_my_computer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb168dd3-eef6-4adf-a4cb-fb439683918b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json  pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "!ls directory_on_my_computer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214eb82f-caf5-4b1b-9eae-5cd1c7ca8d60",
   "metadata": {},
   "source": [
    "If you take a look at the config.json file, youâ€™ll recognize the attributes necessary to build the model architecture. This file also contains some metadata, such as where the checkpoint originated and what ðŸ¤— Transformers version you were using when you last saved the checkpoint.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c6c1e-a8bc-4900-b769-9414fd05d123",
   "metadata": {},
   "source": [
    "The pytorch_model.bin file is known as the state dictionary; it contains all your modelâ€™s weights. The two files go hand in hand; the configuration is necessary to know your modelâ€™s architecture, while the model weights are your modelâ€™s parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01009a4a-7171-4aec-9bb9-6fa2c06e4a52",
   "metadata": {},
   "source": [
    "## Using a Transformer model for inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65708c28-f2a8-4773-a849-02d05994d154",
   "metadata": {},
   "source": [
    "Now that you know how to load and save a model, letâ€™s try using it to make some predictions. Transformer models can only process numbers â€” numbers that the tokenizer generates. But before we discuss tokenizers, letâ€™s explore what inputs the model accepts.\n",
    "\n",
    "Tokenizers can take care of casting the inputs to the appropriate frameworkâ€™s tensors, but to help you understand whatâ€™s going on, weâ€™ll take a quick look at what must be done before sending the inputs to the model.\n",
    "\n",
    "Letâ€™s say we have a couple of sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24322506-c1f8-4138-b816-6a3a33d225c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [\n",
    "  \"Hello!\",\n",
    "  \"Cool.\",\n",
    "  \"Nice!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "520ed59a-d53f-4cf1-a3ae-1ce486844bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cc1675-9a62-4d50-aa0c-c0f4f0515c53",
   "metadata": {},
   "source": [
    "The tokenizer converts these to vocabulary indices which are typically called input IDs. Each sequence is now a list of numbers! The resulting output is:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afc94421-a56a-49e9-bf13-196f1a839dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"np\")['input_ids'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423126cd-a058-4236-9f8d-2cea790bb1da",
   "metadata": {},
   "source": [
    "This is a list of encoded sequences: a list of lists. Tensors only accept rectangular shapes (think matrices). This â€œarrayâ€ is already of rectangular shape, so converting it to a tensor is easy:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "904b2b83-c4c8-4b6d-b199-0c69206ce564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[101, 7592, 999, 102], [101, 4658, 1012, 102], [101, 3835, 999, 102]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d8a2111-747f-47af-a1d5-3254a4b0cc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model_inputs= torch.tensor(encoded_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a48036-af66-4f5e-a808-8dfc007c845a",
   "metadata": {},
   "source": [
    "## Using the tensors as inputs to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9935cd5-9dec-4407-97d7-cd902f31423a",
   "metadata": {},
   "source": [
    "Making use of the tensors with the model is extremely simple â€” we just call the model with the inputs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0480be03-a55d-4f2f-8191-e1d05cdf3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(model_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2bd999-3a42-4587-b8e7-8d76d6c398e0",
   "metadata": {},
   "source": [
    "While the model accepts a lot of different arguments, only the input IDs are necessary. Weâ€™ll explain what the other arguments do and when they are required later, but first we need to take a closer look at the tokenizers that build the inputs that a Transformer model can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17dbdbf2-569d-4916-a8c3-cc0fcf92dbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 4.4495761e-01,  4.8276371e-01,  2.7797160e-01, ...,\n",
       "         -5.4033030e-02,  3.9393550e-01, -9.4770476e-02],\n",
       "        [ 2.4942905e-01, -4.4092986e-01,  8.1772316e-01, ...,\n",
       "         -3.1916568e-01,  2.2992224e-01, -4.1171860e-02],\n",
       "        [ 1.3667573e-01,  2.2517854e-01,  1.4501970e-01, ...,\n",
       "         -4.6914764e-02,  2.8224215e-01,  7.5565711e-02],\n",
       "        [ 1.1788858e+00,  1.6738428e-01, -1.8187094e-01, ...,\n",
       "          2.4671389e-01,  1.0440769e+00, -6.1963657e-03]],\n",
       "\n",
       "       [[ 3.6435887e-01,  3.2464445e-02,  2.0257673e-01, ...,\n",
       "          6.0110606e-02,  3.2451311e-01, -2.0995857e-02],\n",
       "        [ 7.1865958e-01, -4.8725188e-01,  5.1740414e-01, ...,\n",
       "         -4.4012007e-01,  1.4553043e-01, -3.7544787e-02],\n",
       "        [ 3.3223268e-01, -2.3270920e-01,  9.4876043e-02, ...,\n",
       "         -2.5268158e-01,  3.2171968e-01,  8.1144931e-04],\n",
       "        [ 1.2523224e+00,  3.5754374e-01, -5.1319774e-02, ...,\n",
       "         -3.7839824e-01,  1.0526477e+00, -5.6254929e-01]],\n",
       "\n",
       "       [[ 2.4042279e-01,  1.4717807e-01,  1.2110322e-01, ...,\n",
       "          7.6061383e-02,  3.3564422e-01,  2.8261703e-01],\n",
       "        [ 6.5700608e-01, -3.2786563e-01,  2.4967636e-01, ...,\n",
       "         -2.5919503e-01,  2.0174697e-01,  3.3275124e-01],\n",
       "        [ 2.0159565e-01,  1.5782695e-01,  9.8972665e-03, ...,\n",
       "         -3.8850451e-01,  4.1307476e-01,  3.9731979e-01],\n",
       "        [ 1.0174978e+00,  6.4386749e-01, -7.8146571e-01, ...,\n",
       "         -4.2109141e-01,  1.0925057e+00, -4.8456397e-02]]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4246950d-ff44-43ed-b63d-cb0ab7a33ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
